{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Pose Estimation with Mediapipe\n",
    "\n",
    "## https://pypi.org/project/mediapipe/\n",
    "\n",
    "## https://google.github.io/mediapipe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an optimised multiplatform __FREE__ opensource package with Python bindings, meaning you can use it in Python.\n",
    "\n",
    "Do note that some functions are not available in Python yet.\n",
    "\n",
    "You can `pip` install it:\n",
    "\n",
    "```\n",
    "python -m pip install mediapipe\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV. Is always called 'cv2' for some reason. Presumably historically.\n",
    "import mediapipe as mp  # MediaPipe - the pose estimation engine.\n",
    "import time  # An in-built Python library managing Time functions. \n",
    "import numpy as np\n",
    "\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.VideoCapture('a.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body parts list aas per: https://google.github.io/mediapipe/solutions/pose.html\n",
    "\n",
    "BODY_PARTS ={\"Nose\":0,\n",
    "\t\t\t \"L_eye_inner\":1,\n",
    "\t\t\t \"L_eye\":2,\n",
    "\t\t\t \"L_eye_outer\":3,\n",
    "\t\t\t \"R_eye_inner\":4,\n",
    "\t\t\t \"R_eye\":5,\n",
    "\t\t\t \"R_eye_outer\":6,\n",
    "\t\t\t \"L_ear\":7,\n",
    "\t\t\t \"R_ear\":8,\n",
    "\t\t\t \"L_mouth\":9,\n",
    "\t\t\t \"R_mouth\":10,\n",
    "\t\t\t \"L_shoulder\":11,\n",
    "\t\t\t \"R_shoulder\":12,\n",
    "\t\t\t \"L_elbow\":13,\n",
    "\t\t\t \"R_elbow\":14,\n",
    "\t\t\t \"L_wrist\":15,\n",
    "\t\t\t \"R_wrist\":16,\n",
    "\t\t\t \"L_pinky\":17,\n",
    "\t\t\t \"R_pinky\":18,\n",
    "\t\t\t \"L_index\":19,\n",
    "\t\t\t \"R_index\":20,\n",
    "\t\t\t \"L_thumb\":21,\n",
    "\t\t\t \"R_thumb\":22,\n",
    "\t\t\t \"L_hip\":23,\n",
    "\t\t\t \"R_hip\":24,\n",
    "\t\t\t \"L_knee\":25,\n",
    "\t\t\t \"R_knee\":26,\n",
    "\t\t\t \"L_ankle\":27,\n",
    "\t\t\t \"R_ankle\":28,\n",
    "\t\t\t \"L_heel\":29,\n",
    "\t\t\t \"R_heel\":30,\n",
    "\t\t\t \"L_foot_index\":31,\n",
    "\t\t\t \"R_foot_index\":32,\n",
    "\t\t\t }\n",
    "\n",
    "BODY_PARTS_ID = {}\n",
    "for key in BODY_PARTS:\n",
    "\tBODY_PARTS_ID[BODY_PARTS[key]] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_x = np.zeros(3)\n",
    "coords_y = np.zeros(3)\n",
    "\n",
    "pTime = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "\tsuccess, img = cap.read()\n",
    "\timgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\tresults = pose.process(imgRGB)\n",
    "\t# print(results.pose_landmarks)\n",
    "\tif results.pose_landmarks:\n",
    "\t\tmpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "\t\tfor id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "\t\t\th, w,c = img.shape\n",
    "\t\t\t# print(id, lm)\n",
    "\t\t\tcx, cy = int(lm.x*w), int(lm.y*h)\n",
    "\t\t\tcv2.circle(img, (cx, cy), 5, (255,0,0), cv2.FILLED)\n",
    "\t\t\tcv2.putText(img, str(BODY_PARTS_ID[id]), (cx+5,cy+10), cv2.FONT_HERSHEY_SIMPLEX,0.8,(220,220,220), 3)\n",
    "\n",
    "\t\tr_shoulder = results.pose_landmarks.landmark[BODY_PARTS['R_shoulder']]\n",
    "\t\tl_shoulder = results.pose_landmarks.landmark[BODY_PARTS['L_shoulder']]\n",
    "\t\tsh_x = int(w * (r_shoulder.x + l_shoulder.x) / 2)\n",
    "\t\tsh_y = int(h * (r_shoulder.y + l_shoulder.y) / 2)\n",
    "\n",
    "\t\tr_hip = results.pose_landmarks.landmark[BODY_PARTS['R_hip']]\n",
    "\t\tl_hip = results.pose_landmarks.landmark[BODY_PARTS['L_hip']]\n",
    "\t\thip_x = int(w * (r_hip.x + l_hip.x) / 2)\n",
    "\t\thip_y = int(h * (r_hip.y + l_hip.y) / 2)\n",
    "\n",
    "\t\tr_ankle = results.pose_landmarks.landmark[BODY_PARTS['R_ankle']]\n",
    "\t\tl_ankle = results.pose_landmarks.landmark[BODY_PARTS['L_ankle']]\n",
    "\t\tank_x = int(w * (r_ankle.x + l_ankle.x) / 2)\n",
    "\t\tank_y = int(h * (r_ankle.y + l_ankle.y) / 2)\n",
    "\n",
    "\t\tcv2.line(img, (sh_x, sh_y), (hip_x, hip_y), (0,256,0), 3)\n",
    "\t\tcv2.line(img, (hip_x, hip_y), (ank_x, ank_y), (0,256,0), 3)\n",
    "\n",
    "\n",
    "\t\tcoords_x = np.array([sh_x, hip_x, ank_x])\n",
    "\t\tcoords_y = np.array([sh_y, hip_y, ank_y])\n",
    "\t\tbox_width = coords_x.max() - coords_x.min()\n",
    "\t\tbox_height = coords_y.max() - coords_y.min()\n",
    "\t\tbox_ratio = box_height / box_width\n",
    "\t\tif box_ratio < 0.5:\n",
    "\t\t\tprint('FALL!')\n",
    "\t\t\tcv2.rectangle(img,\n",
    "\t\t\t              (coords_x.min(),coords_y.max() ),\n",
    "\t\t\t              (coords_x.max(),coords_y.min() ),\n",
    "\t\t\t\t\t\t  (0,0,255),\n",
    "\t\t\t\t\t\t  5\n",
    "\t\t\t\t\t\t  )\n",
    "\n",
    "\t# Keep timing code together for simplicity\n",
    "\tcTime = time.time()  # Update Current frame time\n",
    "\tfps = 1/(cTime-pTime)  # Calculate framerate\n",
    "\tpTime = cTime  # Update 'previous' frame time\n",
    "\n",
    "\tcv2.putText(img, str(int(fps)), (50,50), cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0), 3)\n",
    "\tcv2.imshow(\"Image\", img)\n",
    "\tcv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
